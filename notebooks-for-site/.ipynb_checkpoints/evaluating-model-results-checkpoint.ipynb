{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating model results \n",
    "\n",
    "**P** - Real positive condition  \n",
    "\n",
    "**N** - Real condition negative\n",
    "\n",
    "**TP** - True positive  - positive hit \n",
    "\n",
    "**TN** - True negative - negative hit\n",
    "\n",
    "**FP** - False positive miss (realitiy is negative)\n",
    "\n",
    "**FN** - False negative - negative miss (reality is positive)\n",
    "\n",
    "Examples will be given in medical case: we have a population of sick and healthy patients. We want to evaluate effectivness of a test. \n",
    "\n",
    "\n",
    "**(TPR) True positive rate** or _sensitivity_ or hit rate  - _probablity of detection a positive test result for a sick patient_ This is the goal! We want to have this as cloase to 1 as possible. It can't be more than 1. If TPR is low it means a lot of False Negative. it means we miss a lot !\n",
    "\n",
    "$$ TPR = \\frac{TP(True~Positive~hit)}{P( REAL~Positive)} = \\frac{TP}{TP+FN}$$ \n",
    "\n",
    "**(TNR) True negative rate** _specificity_ - \n",
    "_probability of a negative test rezult for a good patient_\n",
    "$$ TNR=\\frac{TN}{N}=\\frac{TN}{TN+FP} $$\n",
    "If this one is low it means a lot of False Positive. so the test  gives a lot of false alarm.\n",
    "\n",
    "**FPR**  -  False positive rate, fall out\n",
    "$$FPR=\\frac{FP}{FP+TN}={1-TNR}$$\n",
    "\n",
    "**Precision** - positive predictive value - \n",
    " \n",
    " $$PPV=\\frac{TP}{TP+FP}=\\frac{TP}{All~Predicted~Positive}$$\n",
    "\n",
    "PPV depends on precent of positve cases in  population. Precision ( True Positives / (True Positives + False Positives) ) is highly sensitive to False Positives and is not impacted by a large total real negative denominator. \n",
    "\n",
    "\n",
    "Values ensitivity and specificity are agnostic to the percent of positive cases in the population \n",
    "PR- precigion\n",
    "RC- recall \n",
    "\n",
    "$$ F1 = 2* \\frac {PPV*TPR}{PPV+TPR}=({PPV}^-1 + {TPR}^-1)^-1 $$\n",
    "\n",
    "**Real values for F1** \n",
    "ideal (not possible)\n",
    "PR= 1, RC=1\n",
    "F1= 1\n",
    "Closer to reality: \n",
    "PR=0.75 (significant false positive)  RC=0.85 (some false negative)\n",
    "F1=2*(0.75*0.85)/(0.75+0.85)=0.796\n",
    "\n",
    "## Receiver operating characteristic (ROC) and  Total Operating Characteristic (TOC)\n",
    "\n",
    "ROC is a  graphical plot that illustrates diagnostic ability of a binary  classifier system as its discrimination treshold is varied. \n",
    "\n",
    "ROC curve created by plotting True positve rate (TPR) against False positive rate (FPR) at various treshold settings or ROC reveals two ratios, TP/(TP + FN) and FP/(FP + TN).  \n",
    "\n",
    "Given Treshhold parameter T for continues random observation _X_ if it belongs to cleaa positive \n",
    "\n",
    "$$ TPR(T) = \\int_T^{\\infty}f_1(x)dx$$\n",
    "\n",
    "\n",
    "TOC shows the total information in the contingency table for each threshold\n",
    "For each threshold, ROC reveals two ratios, TP/(TP + FN) and FP/(FP + TN). \n",
    "\n",
    "$$\\sum_{i=1}^{2n}=n*\\frac{n+1}{n-1}$$\n",
    "$$\\frac{du}{dt}$$\n",
    "$$\\int_0^{r}f(x)dx$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
